quarkus.langchain4j.ollama.chat-model.model-name=llama3.1:8b
quarkus.langchain4j.ollama.timeout=120s

quarkus.langchain4j.tavily.api-key=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
quarkus.langchain4j.tavily.max-results=3
quarkus.langchain4j.tavily.log-requests=true

quarkus.log.category."dev.langchain4j".level=DEBUG