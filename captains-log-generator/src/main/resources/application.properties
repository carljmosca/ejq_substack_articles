quarkus.langchain4j.ollama.chat-model.model-id=llama3.1:8b
quarkus.langchain4j.ollama.log-requests=true
quarkus.langchain4j.ollama.log-responses=true
quarkus.langchain4j.ollama.temperature=0.0
quarkus.langchain4j.ollama.timeout=30s