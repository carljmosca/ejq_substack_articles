quarkus.langchain4j.ollama.chat-model.model-id=llama3.1:8b
# Optional but reccomended: Set a timeout
quarkus.langchain4j.ollama.timeout=120s
quarkus.langchain4j.ollama.log-requests=true