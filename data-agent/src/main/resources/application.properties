quarkus.langchain4j.ollama.chat-model.model-id=qwen2.5
quarkus.langchain4j.ollama.timeout=40s
#quarkus.langchain4j.ollama.log-requests=true
#quarkus.langchain4j.ollama.log-responses=true
#quarkus.langchain4j.ollama.chat-model.log-requests=true
#quarkus.langchain4j.ollama.chat-model.log-responses=true
quarkus.langchain4j.ollama.mistral.log-requests=true
quarkus.langchain4j.ollama.mistral.log-responses=true
quarkus.log.level=FINER
